{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"MnistTraining.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPJzw3q0+QPQbZQhVHSqpjQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"Mk35ipm60mfP"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","\"\"\"\n","A model to classify the quintessential MNIST\n","\"\"\""],"outputs":[],"metadata":{"id":"BMYcoK7w009N"}},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"fofYcwdk0noJ"}},{"cell_type":"code","execution_count":null,"source":["#get dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train/255.0, x_test/255.0\n","\n","#add a channels dimension\n","x_train = x_train[..., tf.newaxis].astype(\"float32\")\n","x_test = x_test[..., tf.newaxis].astype(\"float32\")\n","\n","#shuffle and batch the dataset\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"],"outputs":[],"metadata":{"id":"cvsfxQgi1BMC"}},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"MH8v-w570oIt"}},{"cell_type":"code","execution_count":null,"source":["#create model\n","class MyModel(keras.Model):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu', input_shape = (28,28,1))\n","        self.flatten = keras.layers.Flatten()\n","        self.d1 = keras.layers.Dense(128, activation='relu')\n","        self.drop1 = keras.layers.Dropout(.2)\n","        self.d2 = keras.layers.Dense(10)\n","    \n","    def call(self, x):\n","        x = self.conv1(x)\n","        x = self.flatten(x)\n","        x = self.d1(x)\n","        x = self.drop1(x)\n","        x = self.d2(x)\n","        return x\n","\n","#choose loss function and optimizer\n","model = MyModel()\n","loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","optimizer = keras.optimizers.Adam()\n","\n","#select metrics to measure training progress over epochs\n","train_loss = keras.metrics.Mean(name='train_loss')\n","train_accuracy = keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = keras.metrics.Mean(name='test_loss')\n","test_accuracy = keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"outputs":[],"metadata":{"id":"lrd3BQ6R1Kh8"}},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"O-P-rlh_0w0r"}},{"cell_type":"code","execution_count":null,"source":["#do a training step\n","@tf.function\n","def train_step(images, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images, training=True)\n","        loss = loss_object(labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    train_loss(loss)\n","    train_accuracy(labels, predictions)\n","\n","#do a test step\n","@tf.function\n","def test_step(images, labels):\n","    predictions = model(images, training=False)\n","    t_loss = loss_object(labels, predictions)\n","\n","    test_loss(t_loss)\n","    test_accuracy(labels, predictions)"],"outputs":[],"metadata":{"id":"V4TmjgHtCWsF"}},{"cell_type":"code","execution_count":null,"source":["#train\n","EPOCHS = 5\n","for x in range(EPOCHS):\n","    #reset metrics at beginning of each epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    test_loss.reset_states()\n","    test_accuracy.reset_states()\n","\n","    for images, labels in train_ds:\n","        train_step(images, labels)\n","    \n","    for images, labels in test_ds:\n","        test_step(images, labels)\n","\n","    print(\n","        f'Epoch {x+1}, '\n","        f'Loss: {train_loss.result()} '\n","        f'Accuracy: {train_accuracy.result()*100}, '\n","        f'Test Loss: {test_loss.result()}, '\n","        f'Test Accuracy: {test_accuracy.result()*100}'\n","    )"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.16067983210086823 Accuracy: 95.17666625976562, Test Loss: 0.06209205463528633, Test Accuracy: 97.87999725341797\n","Epoch 2, Loss: 0.056645724922418594 Accuracy: 98.18500518798828, Test Loss: 0.05078515782952309, Test Accuracy: 98.33999633789062\n","Epoch 3, Loss: 0.035098131746053696 Accuracy: 98.86500549316406, Test Loss: 0.051028694957494736, Test Accuracy: 98.47000122070312\n","Epoch 4, Loss: 0.024233978241682053 Accuracy: 99.2066650390625, Test Loss: 0.04713011533021927, Test Accuracy: 98.50999450683594\n","Epoch 5, Loss: 0.018569566309452057 Accuracy: 99.40666198730469, Test Loss: 0.05826923996210098, Test Accuracy: 98.52999877929688\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrB2e7x40ODf","executionInfo":{"status":"ok","timestamp":1654801530725,"user_tz":240,"elapsed":36521,"user":{"displayName":"Domenico Valles","userId":"04978529290284474814"}},"outputId":"e306b5aa-8dc5-48fb-ce19-7a752905e0ba"}}]}